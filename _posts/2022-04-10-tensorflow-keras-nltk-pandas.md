---
title: dependencies
author: Chad Doebelin
date: 2022-04-10
---


Dependencies
: Dependencies are all of the software components required by your project in order for it to work as intended and avoid runtime errors

Some of the dependencies that we need to might need to install are:
- **tensorflow** (https://tensorflow.org/)
- **keras** (https://keras.io)
- **nltk** (https://www.nltk.org/)
- **pandas** (https://pandas.pydata.org/)
- **scikit learn** (https://scikit-learn.org/stable/)
- **numpy** (https://numpy.org/)


We will use **pip** to install them


# Tensorflow is an open source library for ML and AI. 
## this framework
- provides methods to directly create Deep Learning Models
- created by google
- library that invokes C++
- constructs and execute dataflow graphs
(https://www.datasciencecentral.com/understanding-dataflow-graphs-in-tensorflow/)

```
pip install tensorflow
```


# Keras is an open source library that provides an interface for #Neural Networks
- Keras interfaces the TensorFlow library
- high level interface 
- api
- provides clean and simplfied way to create deep learning models using tensorflow

(https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)
(https://www.simplilearn.com/tutorials/deep-learning-tutorial/deep-learning-algorithm)


```
pip install keras
```


# NLTK Natural Language Tool Kit

- suite of libraries for symbolic and statistical natural language processing

- Natural Language Processing explores the relationship between computers and human language.

- The goal of which is for computers to comprehend text and language with human-like recognition.


Primer:
# Main Approaches
## Symbolic Aproach:(https://www.expert.ai/blog/natural-language-processing/)
- human developed rules and lexicons - rules of speech
- synthsization flows from linguistic expert training

## Statistical approrach
- Identifies trends in samples, the system is able to develop its own linguistic rules which are developed to further 
- improve its understanding for generating language outputs.

## connectionist approach 
- a combination of the two previous aproaches, starting with generally accepted rules, further refinements are made using statically derrived inferences.

# Pandas 

- this library contains tools for manipulation and data analysis 
- containing operations for working with time series and quanative data.
- fill, normalization, joins, and cleaning.
(https://www.activestate.com/resources/quick-reads/what-is-pandas-in-python-everything-you-need-to-know/)

```
pip install pandas
```


# NumPy
-this core package adds supportfor the manipulation of arrays and matricies.
(https://www.w3schools.com/python/numpy/numpy_intro.asp)

```
pip install numpy
```


# Scikit Learn
- predicitve data analytsius tools
- built on numpy, scipy and matplotlib

```
pip install scikit
```
